{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2760a4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.indexing.github_parsing import GitHubParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ee2d79d-772b-4b64-b4af-58d14d71ebe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://github.com/huggingface/transformers\"\n",
    "parser = GitHubParser(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aceb315a-d7eb-424e-8d1e-4e2f554322c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('huggingface', 'transformers', None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.parse_url(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19476588-99e7-4f80-81f1-01dcd8428cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'huggingface'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(parser.owner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fdf2cf24-3ceb-431f-ae2f-681940a3df86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'transformers'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(parser.repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9198fbf8-657f-42b6-93a3-f0d14a7e1002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(parser.ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7f3a4cd-41f9-4e44-b584-35111e5e40aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL: https://codeload.github.com/huggingface/transformers/zip/master\n",
      "Response status code: 404\n",
      "URL: https://codeload.github.com/huggingface/transformers/zip/main\n",
      "Response status code: 200\n"
     ]
    }
   ],
   "source": [
    "zipb = parser.fetch_repo_zip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8243fe4-6137-4b37-b638-37df5aa1eba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL: https://codeload.github.com/huggingface/transformers/zip/master\n",
      "Response status code: 404\n",
      "URL: https://codeload.github.com/huggingface/transformers/zip/main\n",
      "Response status code: 200\n"
     ]
    }
   ],
   "source": [
    "from app.indexing.github_parsing import GitHubParser\n",
    "url = \"https://github.com/huggingface/transformers\"\n",
    "parser = GitHubParser(url)\n",
    "\n",
    "elements = parser.parse_repo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d597f2ae-c499-4a77-b8b1-0ea6f924d17c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CodeElement(text='<!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\\nthe License. You may obtain a copy of the License at\\n\\nhttp://www.apache.org/licenses/LICENSE-2.0\\n\\nUnless required by applicable law or agreed to in writing, software distributed under the License is distributed on\\nan \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\\n\\n⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be\\nrendered properly in your Markdown viewer.\\n\\n-->\\n\\n\\n# Efficient Training on Multiple CPUs\\n\\n1つのCPUでのトレーニングが遅すぎる場合、複数のCPUを使用できます。このガイドは、PyTorchベースのDDPを使用した分散CPUトレーニングに焦点を当てています。\\n\\n## Intel® oneCCL Bindings for PyTorch\\n\\n[Intel® oneCCL](https://github.com/oneapi-src/oneCCL)（集合通信ライブラリ）は、allreduce、allgather、alltoallなどの収集通信を実装した効率的な分散ディープラーニングトレーニング用のライブラリです。oneCCLの詳細については、[oneCCLドキュメント](https://spec.oneapi.com/versions/latest/elements/oneCCL/source/index.html)と[oneCCL仕様](https://spec.oneapi.com/versions/latest/elements/oneCCL/source/index.html)を参照してください。\\n\\nモジュール`oneccl_bindings_for_pytorch`（バージョン1.12以前は`torch_ccl`）は、PyTorch C10D ProcessGroup APIを実装し、外部のProcessGroupとして動的にロードでき、現在はLinuxプラットフォームでのみ動作します。\\n\\n[torch-ccl](https://github.com/intel/torch-ccl)の詳細情報を確認してください。\\n\\n### Intel® oneCCL Bindings for PyTorch installation:\\n\\nWheelファイルは、以下のPythonバージョン用に利用可能です:\\n\\n| Extension Version | Python 3.6 | Python 3.7 | Python 3.8 | Python 3.9 | Python 3.10 |\\n| :---------------: | :--------: | :--------: | :--------: | :--------: | :---------: |\\n| 1.13.0            |            | √          | √          | √          | √           |\\n| 1.12.100          |            | √          | √          | √          | √           |\\n| 1.12.0            |            | √          | √          | √          | √           |\\n| 1.11.0            |            | √          | √          | √          | √           |\\n| 1.10.0            | √          | √          | √          | √          |             |\\n\\n```bash\\npip install oneccl_bind_pt=={pytorch_version} -f https://developer.intel.com/ipex-whl-stable-cpu\\n```\\n\\nwhere `{pytorch_version}` should be your PyTorch version, for instance 1.13.0.\\nCheck more approaches for [oneccl_bind_pt installation](https://github.com/intel/torch-ccl).\\nVersions of oneCCL and PyTorch must match.\\n\\n<Tip warning={true}>\\n\\noneccl_bindings_for_pytorch 1.12.0 prebuilt wheel does not work with PyTorch 1.12.1 (it is for PyTorch 1.12.0)\\nPyTorch 1.12.1 should work with oneccl_bindings_for_pytorch 1.12.100\\n\\n</Tip>\\n\\n`{pytorch_version}` は、あなたのPyTorchのバージョン（例：1.13.0）に置き換える必要があります。重要なのは、oneCCLとPyTorchのバージョンが一致していることです。[oneccl_bind_ptのインストール](https://github.com/intel/torch-ccl)に関するさらなるアプローチを確認できます。\\n\\n<Tip warning={true}>\\n\\n`oneccl_bindings_for_pytorch`の1.12.0プリビルトホイールはPyTorch 1.12.1と互換性がありません（これはPyTorch 1.12.0用です）。PyTorch 1.12.1を使用する場合は、`oneccl_bindings_for_pytorch`バージョン1.12.100を使用する必要があります。\\n\\n</Tip>\\n\\n## Intel® MPI library\\n\\n\\nこの基準ベースのMPI実装を使用して、Intel®アーキテクチャ上で柔軟で効率的、スケーラブルなクラスタメッセージングを提供します。このコンポーネントは、Intel® oneAPI HPC Toolkitの一部です。\\n\\noneccl_bindings_for_pytorchはMPIツールセットと一緒にインストールされます。使用する前に環境をソース化する必要があります。\\n\\n\\nfor Intel® oneCCL >= 1.12.0\\n```bash\\noneccl_bindings_for_pytorch_path=$(python -c \"from oneccl_bindings_for_pytorch import cwd; print(cwd)\")\\nsource $oneccl_bindings_for_pytorch_path/env/setvars.sh\\n```\\n\\nfor Intel® oneCCL whose version < 1.12.0\\n```bash\\ntorch_ccl_path=$(python -c \"import torch; import torch_ccl; import os;  print(os.path.abspath(os.path.dirname(torch_ccl.__file__)))\")\\nsource $torch_ccl_path/env/setvars.sh\\n```\\n\\n#### IPEX installation:\\n\\nIPEXは、Float32およびBFloat16の両方でCPUトレーニングのパフォーマンス最適化を提供します。詳細は[こちらのシングルCPUセクション](./perf_train_cpu)をご参照ください。\\n\\n以下の「トレーナーでの使用」は、Intel® MPIライブラリでmpirunを使用する例を示しています。\\n\\n## Usage in Trainer\\nトレーナーでのマルチCPU分散トレーニングを有効にするために、ユーザーはコマンド引数に **`--ddp_backend ccl`** を追加する必要があります。\\n\\n例を見てみましょう。[質問応答の例](https://github.com/huggingface/transformers/tree/main/examples/pytorch/question-answering)\\n\\n以下のコマンドは、1つのXeonノードで2つのプロセスを使用してトレーニングを有効にします。1つのプロセスが1つのソケットで実行されます。OMP_NUM_THREADS/CCL_WORKER_COUNT変数は、最適なパフォーマンスを調整するために調整できます。\\n\\n\\n```shell script\\n export CCL_WORKER_COUNT=1\\n export MASTER_ADDR=127.0.0.1', source='docs/source/ja/perf_train_cpu_many.md', header='', extension='.md', description='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(elements[2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac1001da-5a7f-40d9-87c6-a13b96ab736a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!--Copyright 2023 The HuggingFace Team. All rights reserved.\n",
      "\n",
      "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\n",
      "the License. You may obtain a copy of the License at\n",
      "\n",
      "http://www.apache.org/licenses/LICENSE-2.0\n",
      "\n",
      "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on\n",
      "an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\n",
      "\n",
      "⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be\n",
      "rendered properly in your Markdown viewer.\n",
      "\n",
      "-->\n",
      "\n",
      "\n",
      "# Efficient Training on Multiple CPUs\n",
      "\n",
      "1つのCPUでのトレーニングが遅すぎる場合、複数のCPUを使用できます。このガイドは、PyTorchベースのDDPを使用した分散CPUトレーニングに焦点を当てています。\n",
      "\n",
      "## Intel® oneCCL Bindings for PyTorch\n",
      "\n",
      "[Intel® oneCCL](https://github.com/oneapi-src/oneCCL)（集合通信ライブラリ）は、allreduce、allgather、alltoallなどの収集通信を実装した効率的な分散ディープラーニングトレーニング用のライブラリです。oneCCLの詳細については、[oneCCLドキュメント](https://spec.oneapi.com/versions/latest/elements/oneCCL/source/index.html)と[oneCCL仕様](https://spec.oneapi.com/versions/latest/elements/oneCCL/source/index.html)を参照してください。\n",
      "\n",
      "モジュール`oneccl_bindings_for_pytorch`（バージョン1.12以前は`torch_ccl`）は、PyTorch C10D ProcessGroup APIを実装し、外部のProcessGroupとして動的にロードでき、現在はLinuxプラットフォームでのみ動作します。\n",
      "\n",
      "[torch-ccl](https://github.com/intel/torch-ccl)の詳細情報を確認してください。\n",
      "\n",
      "### Intel® oneCCL Bindings for PyTorch installation:\n",
      "\n",
      "Wheelファイルは、以下のPythonバージョン用に利用可能です:\n",
      "\n",
      "| Extension Version | Python 3.6 | Python 3.7 | Python 3.8 | Python 3.9 | Python 3.10 |\n",
      "| :---------------: | :--------: | :--------: | :--------: | :--------: | :---------: |\n",
      "| 1.13.0            |            | √          | √          | √          | √           |\n",
      "| 1.12.100          |            | √          | √          | √          | √           |\n",
      "| 1.12.0            |            | √          | √          | √          | √           |\n",
      "| 1.11.0            |            | √          | √          | √          | √           |\n",
      "| 1.10.0            | √          | √          | √          | √          |             |\n",
      "\n",
      "```bash\n",
      "pip install oneccl_bind_pt=={pytorch_version} -f https://developer.intel.com/ipex-whl-stable-cpu\n",
      "```\n",
      "\n",
      "where `{pytorch_version}` should be your PyTorch version, for instance 1.13.0.\n",
      "Check more approaches for [oneccl_bind_pt installation](https://github.com/intel/torch-ccl).\n",
      "Versions of oneCCL and PyTorch must match.\n",
      "\n",
      "<Tip warning={true}>\n",
      "\n",
      "oneccl_bindings_for_pytorch 1.12.0 prebuilt wheel does not work with PyTorch 1.12.1 (it is for PyTorch 1.12.0)\n",
      "PyTorch 1.12.1 should work with oneccl_bindings_for_pytorch 1.12.100\n",
      "\n",
      "</Tip>\n",
      "\n",
      "`{pytorch_version}` は、あなたのPyTorchのバージョン（例：1.13.0）に置き換える必要があります。重要なのは、oneCCLとPyTorchのバージョンが一致していることです。[oneccl_bind_ptのインストール](https://github.com/intel/torch-ccl)に関するさらなるアプローチを確認できます。\n",
      "\n",
      "<Tip warning={true}>\n",
      "\n",
      "`oneccl_bindings_for_pytorch`の1.12.0プリビルトホイールはPyTorch 1.12.1と互換性がありません（これはPyTorch 1.12.0用です）。PyTorch 1.12.1を使用する場合は、`oneccl_bindings_for_pytorch`バージョン1.12.100を使用する必要があります。\n",
      "\n",
      "</Tip>\n",
      "\n",
      "## Intel® MPI library\n",
      "\n",
      "\n",
      "この基準ベースのMPI実装を使用して、Intel®アーキテクチャ上で柔軟で効率的、スケーラブルなクラスタメッセージングを提供します。このコンポーネントは、Intel® oneAPI HPC Toolkitの一部です。\n",
      "\n",
      "oneccl_bindings_for_pytorchはMPIツールセットと一緒にインストールされます。使用する前に環境をソース化する必要があります。\n",
      "\n",
      "\n",
      "for Intel® oneCCL >= 1.12.0\n",
      "```bash\n",
      "oneccl_bindings_for_pytorch_path=$(python -c \"from oneccl_bindings_for_pytorch import cwd; print(cwd)\")\n",
      "source $oneccl_bindings_for_pytorch_path/env/setvars.sh\n",
      "```\n",
      "\n",
      "for Intel® oneCCL whose version < 1.12.0\n",
      "```bash\n",
      "torch_ccl_path=$(python -c \"import torch; import torch_ccl; import os;  print(os.path.abspath(os.path.dirname(torch_ccl.__file__)))\")\n",
      "source $torch_ccl_path/env/setvars.sh\n",
      "```\n",
      "\n",
      "#### IPEX installation:\n",
      "\n",
      "IPEXは、Float32およびBFloat16の両方でCPUトレーニングのパフォーマンス最適化を提供します。詳細は[こちらのシングルCPUセクション](./perf_train_cpu)をご参照ください。\n",
      "\n",
      "以下の「トレーナーでの使用」は、Intel® MPIライブラリでmpirunを使用する例を示しています。\n",
      "\n",
      "## Usage in Trainer\n",
      "トレーナーでのマルチCPU分散トレーニングを有効にするために、ユーザーはコマンド引数に **`--ddp_backend ccl`** を追加する必要があります。\n",
      "\n",
      "例を見てみましょう。[質問応答の例](https://github.com/huggingface/transformers/tree/main/examples/pytorch/question-answering)\n",
      "\n",
      "以下のコマンドは、1つのXeonノードで2つのプロセスを使用してトレーニングを有効にします。1つのプロセスが1つのソケットで実行されます。OMP_NUM_THREADS/CCL_WORKER_COUNT変数は、最適なパフォーマンスを調整するために調整できます。\n",
      "\n",
      "\n",
      "```shell script\n",
      " export CCL_WORKER_COUNT=1\n",
      " export MASTER_ADDR=127.0.0.1\n"
     ]
    }
   ],
   "source": [
    "print(elements[2000].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e79bc595-c7b4-4150-9d0e-a33d97afcd1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and reply to the questions asked. Then\n",
      "\n",
      "```bash\n",
      "accelerate test\n",
      "```\n",
      "\n",
      "that will check everything is ready for training. Finally, you can launch training with\n",
      "\n",
      "```bash\n",
      "accelerate launch run_image_classification_no_trainer.py --image_column_name img\n",
      "```\n",
      "\n",
      "This command is the same and will work for:\n",
      "\n",
      "- single/multiple CPUs\n",
      "- single/multiple GPUs\n",
      "- TPUs\n",
      "\n",
      "Note that this library is in alpha release so your feedback is more than welcome if you encounter any problem using it.\n",
      "\n",
      "Regarding using custom data with this script, we refer to [using your own data](#using-your-own-data).\n"
     ]
    }
   ],
   "source": [
    "print(elements[3000].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b023db5f-d82f-4d1d-8ed1-519808faeab8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
